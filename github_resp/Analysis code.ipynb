{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "# from scipy.spatial.distance import jensenshannon\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.stats import binom_test \n",
    "import scipy.stats\n",
    "\n",
    "import collections\n",
    "from itertools import combinations\n",
    "import string\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import Co_Evo_Func as cef\n",
    "\n",
    "### Preproccessing ###\n",
    "\n",
    "counts = pd.read_excel(\"raw_data/counts_uni.xlsx\", index_col=0)\n",
    "\n",
    "counts['Generation'] = counts['transfer']*10.5  # translate transfers to generations\n",
    "species = counts.loc[:, 'Ea':'IN72'].columns # list of species in the experiment\n",
    "counts['total'] = counts[species].sum(axis = 1) # total counts for each row\n",
    "counts = counts[counts['total']>0]\n",
    "counts['present'] = counts[species].apply(lambda x:x>0, axis = 1).apply(lambda x: list(species[x.values]), axis=1) # which species are present at each count\n",
    "counts = counts[counts['sample_kind'].isin(['Pair', 'Trio'])].reset_index(drop = True) # leave only pairs and trios\n",
    "\n",
    "counts = counts[~counts['transfer'].isin([13, 15])].reset_index(drop = True)\n",
    "# Samples that did not coexsist for atleast 70 generations are taken out of the analysis\n",
    "\n",
    "coexistence = lambda x : True if all([sp in x['present'] for sp in x['sample'].split('_')]) else False\n",
    "counts['coexistence'] = counts.apply(coexistence, axis = 1)\n",
    "\n",
    "excluded = lambda x:[sp for sp in x['sample'].split('_') if sp not in x['present']][0] if len([sp for sp in x['sample'].split('_') if sp not in x['present']]) > 0 else 'non'\n",
    "counts['excluded'] = counts.apply(excluded, axis =1)\n",
    "\n",
    "last_coex = lambda x: max(x['transfer'][x['coexistence']])\n",
    "lc = counts.groupby(['sample_kind','sample','ident'])[['transfer', 'coexistence']].apply(last_coex)\n",
    "lc = pd.DataFrame(lc).reset_index()\n",
    "lc = lc.rename(columns={0: 'last_coex'})\n",
    "lc['excluded'] = lc.apply(lambda x:counts['excluded'][counts['ident']==x['ident']][counts['transfer']==38].values, axis = 1)\n",
    "\n",
    "\n",
    "counts = counts[~counts['ident'].isin(lc['ident'][lc['last_coex']<7])].reset_index(drop = True)\n",
    "counts = counts[counts['sample']!='Pa_Fj'].reset_index(drop = True)\n",
    "\n",
    "#Spot contaminations \n",
    "\n",
    "spot_contaminations = lambda x : False if all([sp in x['sample'].split('_') for sp in x['present']]) else True\n",
    "counts['cont'] = counts.apply(spot_contaminations, axis = 1) # when a species which souldn't be present is present, set cont as True\n",
    "first_cont = lambda x: min(x['transfer'][x['cont']].values) if (len(x['transfer'][x['cont']]) != 0) else 38 \n",
    "fcont = counts[counts['sample_kind'].isin(['Pair', 'Trio'])].groupby(['ident'])[['transfer', 'cont']].apply(first_cont) # If cont == True where did it apear first\n",
    "fcont = pd.DataFrame(fcont).reset_index()\n",
    "for t, ide in zip(fcont[fcont[0]!=38][0], fcont[fcont[0]!=38]['ident']):\n",
    "    # all datapoints after contamination appeared are considered contaminated\n",
    "    counts['cont'][counts['ident']==ide][counts['transfer'] > t] = True\n",
    "contaminated = counts['ident'][counts['cont']].unique()\n",
    "with open(\"proccesed_data/contamination.txt\", \"w\") as output:\n",
    "    output.write(str(contaminated))\n",
    "    \n",
    "counts = counts[~counts['cont']].reset_index(drop = True)\n",
    "\n",
    " # New counts table only with fractions\n",
    "cf = counts.copy() \n",
    "cf[species] = cf[species].apply(lambda x:x/cf['total'])\n",
    "#counts_frac['detection_limit'] = 1/counts_frac['total']\n",
    "\n",
    "only_pairs = cf['present'].apply(lambda x:len(x))==2 #return only columns with 2 species present\n",
    "first_species = lambda x:x.split('_')[0] # return the first species\n",
    "# calculate the std from binome distribution\n",
    "std_binom = lambda x: np.sqrt(x[first_species(x['sample'])]*(1-x[first_species(x['sample'])])/(x['total']+1)) \n",
    "cf['std'] = cf[only_pairs].apply(std_binom, axis = 1)\n",
    "\n",
    " # New counts table only with fractions and pseudocounts\n",
    "    \n",
    "cf_psu = counts.copy() \n",
    "cf_psu = cf_psu.apply(cef.add_pseudocounts, axis = 1)\n",
    "cf_psu['total'] = cf_psu[species].sum(axis = 1)\n",
    "\n",
    "cf_psu[species] = cf_psu[species].apply(lambda x:x/cf_psu['total'])\n",
    "only_pairs = cf_psu['present'].apply(lambda x:len(x))==2 #return only columns with 2 species present\n",
    "first_species = lambda x:x.split('_')[0] # return the first species\n",
    "# calculate the std from binome distribution\n",
    "std_binom = lambda x: np.sqrt(x[first_species(x['sample'])]*(1-x[first_species(x['sample'])])/(x['total']+1)) \n",
    "cf_psu['std'] = cf_psu[only_pairs].apply(std_binom, axis = 1)\n",
    "\n",
    "cf['change'] = cf.groupby('ident')[species].apply(cef.euc_change)# quantify the distance of each timepoint from the last one\n",
    "cf['change'] = cf.apply(lambda x:x['change']/sqrt(len(x['sample'].split('_'))), axis = 1)\n",
    "#cf['Shannon'] = cf.loc[:,'Ea':'IN72'].apply(cef.Shannon, axis = 1) # calculate the alpha diversity for each community\n",
    "cf['dist_from_ee'] = cf.apply(lambda x: euclidean(x[species], cf[species][cf['transfer']==7][cf['ident'] == x['ident']]) if len(cf[species][cf['transfer']==7][cf['ident'] == x['ident']])!= 0 else NaN, axis = 1)\n",
    "cf['dist_from_ee'] = cf.apply(lambda x:x['dist_from_ee']/sqrt(len(x['sample'].split('_'))), axis = 1)\n",
    "cf['dist_from_cent'] = cf.apply(lambda x:euclidean(x[species], cf[species][cf['sample']==x['sample']][cf['transfer']==x['transfer']].mean()), axis =1)\n",
    "\n",
    "\n",
    "OD = pd.read_excel(\"proccesed_data/OD_proccesed.xlsx\") # OD table\n",
    "OD = OD.drop(['Plate', 'Well', 'Z_score', 'growth'], axis =1)\n",
    "\n",
    "frac_od = pd.merge(cf, OD[['ident', 'transfer', 'OD', 'smoothed']], on=['ident', 'transfer'])\n",
    "frac_od[species] = frac_od[species].apply(lambda x:x*frac_od['smoothed'])\n",
    "\n",
    "cf['Gen_jit'] = cf['Generation']+ random.normal(0, 2, len(cf)) #jittered generation for some plots\n",
    "cf['Gen_jit'][cf['transfer']==0] = 0 #don't jitter t0\n",
    "\n",
    "# cf.to_excel('proccesed_data/cf.xlsx', index=False)\n",
    "# cf_psu.to_excel('proccesed_data/cf_psu.xlsx', index=False)\n",
    "# frac_od.to_excel('proccesed_data/frac_od.xlsx', index=False)\n",
    "#counts.to_excel('proccesed_data/counts_proccesed.xlsx', index = False)\n",
    "\n",
    "cf = pd.read_excel('proccesed_data/cf.xlsx') # fractionized count table\n",
    "cf_psu = pd.read_excel('proccesed_data/cf_psu.xlsx') # fractionized count table with pseudocounts\n",
    "frac_od = pd.read_excel('proccesed_data/frac_od.xlsx')\n",
    "\n",
    "OD = pd.read_excel(\"raw_data/OD_proccesed.xlsx\") # OD table\n",
    "OD = OD.drop(['Plate', 'Well', 'Z_score', 'growth'], axis =1)\n",
    "\n",
    "pairs = cf['sample'][cf['sample_kind']=='Pair'].unique() # a list of pairs in the experiment\n",
    "trios = cf['sample'][cf['sample_kind']=='Trio'].unique() # a list of trios in the experiment\n",
    "species = cf.loc[:, 'Ea':'IN72'].columns # list of species in the experiment\n",
    "transfers = cf['transfer'].unique()\n",
    "gens = cf['Generation'].unique()\n",
    "cf['total'][cf.transfer == 0] = cf['total'][cf.transfer == 0] + 10\n",
    "idents = cf['ident'].unique()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
